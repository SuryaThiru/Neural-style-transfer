{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f07d3e6869233660de4c6c8f29255408390acccf",
    "colab_type": "text",
    "id": "-KXqydKuAN7R"
   },
   "source": [
    "# Neural Style Transfer in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fc7ace24f2dbb1d3d2a1e60f706f6018cd07137f",
    "colab_type": "text",
    "id": "Su7-neIuLmoX"
   },
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "4db4234dce4954798fde8b57d92658af937889e8",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4363,
     "status": "ok",
     "timestamp": 1533237414835,
     "user": {
      "displayName": "Surya GCP",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111350851809469475095"
     },
     "user_tz": -330
    },
    "id": "ZdF0bB0i5FgR",
    "outputId": "d8bfe9e0-88ea-4180-ae19-64a39c69d7ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "63cf6c2c783db0e493f24eef27fe2cb59856a417",
    "colab_type": "text",
    "id": "NDjI_o-6mnZs"
   },
   "source": [
    "## Set up files in the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "09b7110556da35d252d1b8918e1e0dd772f694de",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4343,
     "status": "ok",
     "timestamp": 1533237419345,
     "user": {
      "displayName": "Surya GCP",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111350851809469475095"
     },
     "user_tz": -330
    },
    "id": "wdjIEPQ8vU23",
    "outputId": "fe6dff3e-1276-4151-d52e-7aab742db5f5"
   },
   "outputs": [],
   "source": [
    "# !wget https://github.com/AparaV/artistic-style/raw/master/images/originals/river.jpg\n",
    "# !wget https://github.com/AparaV/artistic-style/raw/master/images/originals/starry_night.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "16a99bc6bd02f0a5e6c45ade424240ad8c11868e",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5972,
     "status": "ok",
     "timestamp": 1533237425407,
     "user": {
      "displayName": "Surya GCP",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111350851809469475095"
     },
     "user_tz": -330
    },
    "id": "fkr0pwqwv-ln",
    "outputId": "5881f7fa-dba7-4800-df41-53bce50801df"
   },
   "outputs": [],
   "source": [
    "# !mkdir img\n",
    "# !mkdir output\n",
    "# !mv *.jpg img/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "18cda02246305cc46b0fa563f8b3c4f60c43a594",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3856,
     "status": "ok",
     "timestamp": 1533237429326,
     "user": {
      "displayName": "Surya GCP",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111350851809469475095"
     },
     "user_tz": -330
    },
    "id": "fGJ8hVVPwl65",
    "outputId": "5cc365b0-ab74-4887-af38-35c256e58716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "river.jpg  starry_night.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "10229c9863e9bcecaa7224a294ea39d579b63c79",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "PB28bRP4vJAX"
   },
   "outputs": [],
   "source": [
    "cnt_img_path = 'img/river.jpg'\n",
    "style_img_path = 'img/starry_night.jpg'\n",
    "output_path = 'output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e648000c9a99c07de17aec6f77be354b99b53ea",
    "colab_type": "text",
    "id": "LAB31mmF5M_4"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "62fa67a4c95dec2ca2ae028b7ab065f9fe67c981",
    "code_folding": [],
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jwgfyxmnxfxT"
   },
   "outputs": [],
   "source": [
    "# def imsave(img, path):\n",
    "#     img = post_process_image(img)\n",
    "#     img = Image.fromarray(img)\n",
    "#     img.save(path)\n",
    "\n",
    "def imsave(img, path, target_size=(512, 512), postprocess=True):\n",
    "    if postprocess:\n",
    "        img = postprocess_array(img)\n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize(target_size)\n",
    "    img.save(path)\n",
    "    return img    \n",
    "\n",
    "# def imread(path):\n",
    "#     img = Image.open(path)\n",
    "#     return np.asarray(img)\n",
    "def imread(path, target_size=(512,512)):\n",
    "    img = load_img(path=path, target_size=target_size)\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(np.expand_dims(img, axis=0))\n",
    "    return img\n",
    "\n",
    "def imread_tensor(path, target_size=(512,512)):\n",
    "  # reads an image and returns a preprocessed tensor\n",
    "    img = load_img(path=path, target_size=target_size)\n",
    "    img = img_to_array(img)\n",
    "    img = K.variable(preprocess_input(np.expand_dims(img, axis=0)), dtype='float32')\n",
    "    return img\n",
    "\n",
    "def implot(img):\n",
    "    if type(img) == str: # read from path\n",
    "        img = imread(img)\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "\n",
    "# def post_process_image(image):\n",
    "#     image[:, :, 0] += 103.939\n",
    "#     image[:, :, 1] += 116.779\n",
    "#     image[:, :, 2] += 123.68\n",
    "#     return np.clip(image[:, :, ::-1], 0, 255).astype('uint8')\n",
    "\n",
    "def postprocess_array(x, target_size=(512, 512, 3)):\n",
    "    if x.shape != target_size:\n",
    "        x = x.reshape(target_size)\n",
    "\n",
    "#     x[..., 0] = np.add(x[..., 0], 103.939, casting='unsafe')\n",
    "#     x[..., 1] = np.add(x[..., 1], 116.779, casting='unsafe')\n",
    "#     x[..., 2] = np.add(x[..., 2], 123.68, casting='unsafe')\n",
    "    x[..., 0] += 103.939\n",
    "    x[..., 1] += 116.779\n",
    "    x[..., 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[..., ::-1]\n",
    "    x = np.clip(x, 0, 255)\n",
    "    x = x.astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "82bb11bffc7b508ad47a19fab3a84c154fc03114",
    "colab_type": "text",
    "id": "W6siMQ1WIQ7R"
   },
   "source": [
    "## Implement Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cb9082c8510348ab8c5a99e153bc0c9f86c8accb",
    "colab_type": "text",
    "id": "HItLMSWeA9ja"
   },
   "source": [
    "### Define important operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "679d5d4fc17c30d7ee5245e71d6f95986786d286",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "OtkE0nHAHvgX"
   },
   "outputs": [],
   "source": [
    "def generate_canvas(mode='random', ref_image=None):\n",
    "    ''' Generate a canvas and return a placeholder\n",
    "    modes: random, from_ref\n",
    "    ref_image: pass an img array or path if mode is 'from_ref'\n",
    "    '''\n",
    "    size = (512, 512, 3)\n",
    "\n",
    "    if mode == 'random':\n",
    "        img = np.random.randint(256, size=size)\n",
    "    elif mode == 'from_ref':\n",
    "        if type(ref_image) == str:\n",
    "            img = load_img(path=ref_image, target_size=size)\n",
    "            img = img_to_array(img)\n",
    "        else:\n",
    "            img = ref_image.copy()\n",
    "\n",
    "    img = preprocess_input(np.expand_dims(img, axis=0))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "1385de3b7b748c5497cd3684fe966837d4f89902",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "mU8FcIcToIyG"
   },
   "outputs": [],
   "source": [
    "def get_feature_maps(model, layers):\n",
    "    '''get feature maps for given layers in the required format\n",
    "    '''\n",
    "    features = []\n",
    "\n",
    "    for layer in layers:\n",
    "        feat = model.get_layer(layer).output\n",
    "        shape = K.shape(feat).eval(session=tf_session)\n",
    "        M = shape[1] * shape[2]\n",
    "        N = shape[-1]\n",
    "        feat = K.transpose(K.reshape(feat, (M, N)))\n",
    "        features.append(feat)\n",
    "\n",
    "    return features   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fc4414b1dfeb499ded17bd7ef2bc6f3deda4f396",
    "colab_type": "text",
    "id": "9c07MQn7PC8l"
   },
   "source": [
    "![content loss](https://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "f633877ab0f31a491b851aba3c7e0796c6c32776",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "trBwS1qJIdsE"
   },
   "outputs": [],
   "source": [
    "def content_loss(F, P):\n",
    "    assert F.shape == P.shape\n",
    "    loss = 0.5 * K.sum(K.square(F - P))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "4c8d2a394728fc842f93e81cdf15da36b26172a1",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "XyhGv_DSgIju"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(matrix):\n",
    "    return K.dot(matrix, K.transpose(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "828f9d24328d04c01ab7e3b4b0810beff31bd12e",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "CyCIBID6xCbE"
   },
   "outputs": [],
   "source": [
    "def style_loss(G, A):\n",
    "    ''' Contribution of each layer to the total style loss\n",
    "    '''\n",
    "    assert G.shape == A.shape\n",
    "\n",
    "#     N, M = K.shape(G).eval(session=tf_session)\n",
    "    M, N = K.int_shape(G)[1], K.int_shape(G)[0]\n",
    "    G, A = gram_matrix(G), gram_matrix(A)\n",
    "    loss = 0.25 * K.sum(K.square(G - A)) / ((N ** 2) * (M ** 2))\n",
    "    return loss\n",
    "\n",
    "def total_style_loss(weights, Gs, As):\n",
    "    ''' Get weighted total style loss\n",
    "    '''\n",
    "    loss = K.variable(0)\n",
    "\n",
    "    for w, G, A in zip(weights, Gs, As):\n",
    "        loss = loss + w * style_loss(G, A)\n",
    "\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "5b688887bfef5b1718f7e969981b42048a6407d7",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "CG0UNFzm1p3B"
   },
   "outputs": [],
   "source": [
    "def total_loss(P, As, canvas_model, clayers, slayers, style_weights, alpha=1.0, beta=10000.0):\n",
    "    ''' Get total loss\n",
    "    params:\n",
    "    x: generated image\n",
    "    p: content image features\n",
    "    a: style image features\n",
    "    '''\n",
    "    F = get_feature_maps(canvas_model, clayers)[0]\n",
    "    Gs = get_feature_maps(canvas_model, slayers)\n",
    "\n",
    "    closs = content_loss(F, P)\n",
    "    sloss = total_style_loss(style_weights, Gs, As)\n",
    "\n",
    "    loss = alpha * closs + beta * sloss  \n",
    "    return loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b3275e1f021052a8c3c820efa18f3a30a4fd3b1d",
    "colab_type": "text",
    "id": "FYnMlCpxMoOr"
   },
   "source": [
    "###  Read images and define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "397df88112ddad29d9deaa4bc3d826571a37650f",
    "colab_type": "text",
    "id": "bzpwAiVz8kKC"
   },
   "source": [
    "load all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "f543da928ab496ecdfb9dd9b779ac82e72d16cba",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "J3RPk-QC8Vy1"
   },
   "outputs": [],
   "source": [
    "target_size = (512, 512, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "f52b16ef14d30d8d01639e8d4c41f66c090e75e3",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Qr9Utfrch7H6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt_img = imread_tensor(cnt_img_path)\n",
    "style_img = imread_tensor(style_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8975addddeb413849a5e4f999acfb7ba44082512",
    "colab_type": "text",
    "id": "YWAD85Rm8tAS"
   },
   "source": [
    "setup VGG model and required configuraton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "221210de1997b661da97719baba0df9ca65542a2",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "33sbfJWD8H4w"
   },
   "outputs": [],
   "source": [
    "canvas_placeholder = K.placeholder(shape=(1,)+target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conv_net = VGG16(include_top=False, weights='imagenet', input_tensor=cnt_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "97561ad5a3da6854c2296dbd40041a0ae66fa084",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Shze-wo4hY7a"
   },
   "outputs": [],
   "source": [
    "cnt_model = VGG16(include_top=False, weights='imagenet', input_tensor=cnt_img)\n",
    "style_model = VGG16(include_top=False, weights='imagenet', input_tensor=style_img)\n",
    "canvas_model = VGG16(include_top=False, weights='imagenet', input_tensor=canvas_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "019c6e3942e328b664c075fc297c4c063364615a",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "0bp0cxXUnE0F"
   },
   "outputs": [],
   "source": [
    "tf_session = K.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "654e67b8513a57bd8446d4e2360aefdc26865c97",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "MvF6FRRLLqJR"
   },
   "outputs": [],
   "source": [
    "cnt_layers = ['block4_conv2']\n",
    "style_layers = [\n",
    "                'block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "]\n",
    "Ws = [1.0 / float(len(style_layers))] * len(style_layers) # weights for each style layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "89f16a2cf3e498c21ff26a0e353e5084c732777c",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "h3Wb0Q_d9pvP"
   },
   "outputs": [],
   "source": [
    "P = get_feature_maps(cnt_model, cnt_layers)[0]\n",
    "As = get_feature_maps(style_model, style_layers)\n",
    "\n",
    "X = generate_canvas('from_ref', cnt_img_path).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9777147642f8e540704a35d77afafbffcab508be",
    "colab_type": "text",
    "id": "mIDitv-f9XO9"
   },
   "source": [
    "## Optimize the distance between content and style image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e317bf7e1d7b03351edf7bfeb4a1be6c80b605a",
    "colab_type": "text",
    "id": "rApmO-A8-HWG"
   },
   "source": [
    "Define function to use with scipy optimizers. The total loss function is optimized using the **limited-memory BFGS** optimizer.\n",
    "\n",
    "L-BFGS is a second order optimization method that works compared well to other popular methods when memory requirements can't be met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "3f79101898ca0bb1cc5a6e6d1d20e5b14cce17c2",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vm1gwk86U5sO"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "save_per_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "ea1517626c0e6efe120b2e2cdc8282990ae6a12f",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SGNA01BpMMQY"
   },
   "outputs": [],
   "source": [
    "# gimg - generated image in the canvas\n",
    "\n",
    "step = 1\n",
    "\n",
    "def calculate_loss(gimg):\n",
    "    gimg = gimg.reshape((1,)+target_size)\n",
    "\n",
    "    loss = total_loss(P, As, canvas_model, cnt_layers, style_layers, Ws)\n",
    "    loss_func = K.function([canvas_model.input], [loss])\n",
    "    return loss_func([gimg])[0].astype('float64')\n",
    "\n",
    "def calculate_grad(gimg):\n",
    "    gimg = gimg.reshape((1,)+target_size)\n",
    "\n",
    "    loss = total_loss(P, As, canvas_model, cnt_layers, style_layers, Ws)\n",
    "    gradients = K.gradients(loss, [canvas_model.input])\n",
    "    grad_func = K.function([canvas_model.input], gradients)\n",
    "    return grad_func([gimg])[0].flatten().astype('float64')\n",
    "\n",
    "def callback(gimg):\n",
    "    global step\n",
    "\n",
    "    print(f'\\rStep: {step}/{epochs}', end='')\n",
    "    step += 1\n",
    "\n",
    "    if (step % save_per_epoch) == 0 or (step == epochs):\n",
    "        gimg = gimg.copy()\n",
    "#         gimg = gimg.reshape(target_size)-+\n",
    "        path = output_path + f'out_{step}.jpg'\n",
    "        imsave(gimg, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "4f7974d5e6f4a938d2a9bc314724907e32c6aa82",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "vEk2MbUaZqr8"
   },
   "outputs": [],
   "source": [
    "# bounds = np.ndarray(shape=(X.shape[0], 2))\n",
    "# bounds[:, 0] = -128.0\n",
    "# bounds[:, 1] = 128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "8a7031da87d2371f9ae2b53b41667eabd793447b",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "pYL3l-rYCjWX",
    "outputId": "a4ed9a84-0722-4b66-b9c8-b65b3c36c8af",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 31/30"
     ]
    }
   ],
   "source": [
    "X_optim, _, info = fmin_l_bfgs_b(calculate_loss, X, fprime=calculate_grad, maxiter=epochs, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d1d5b360d55c3282c9f83f9d53aa5e006758ff4c",
    "colab_type": "text",
    "id": "grxlTQ-YKkJW"
   },
   "source": [
    "## View the generated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = output_path + 'optimal.jpg'\n",
    "imsave(XX_optim, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "3307dc518994ca8e79ecf706a1b1c950ee84b04e",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "-YGj0xRBKChf"
   },
   "outputs": [],
   "source": [
    "# img = X_optim.reshape(target_size)\n",
    "# # img = postprocess_array(img)\n",
    "# implot(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "d05ed93ccfe2128b2022184c0b1bb29bae87b965",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3463,
     "status": "ok",
     "timestamp": 1533237605971,
     "user": {
      "displayName": "Surya GCP",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111350851809469475095"
     },
     "user_tz": -330
    },
    "id": "hP3w2x_3IbMG",
    "outputId": "f849c55b-50e0-4139-e6c0-900975a5e106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_10.jpg  out_20.jpg\tout_30.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!ls output"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Su7-neIuLmoX",
    "NDjI_o-6mnZs",
    "HItLMSWeA9ja",
    "FYnMlCpxMoOr"
   ],
   "default_view": {},
   "name": "Neural style transfer.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
